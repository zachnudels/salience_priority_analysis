# -*- coding: utf-8 -*-
"""
Created on Mon Jan 30 10:09:12 2017

@author: Jonathan
"""
# ==============================================================================
# Imports
# ==============================================================================
import re
import math
import numpy as np
import scipy.signal as sign
import pandas as pd
from collections import deque
import traceback


# ==============================================================================
# Functions
# ==============================================================================
def pixDist(x, y):
    return np.hstack([[0], np.sqrt((x[:-1] - x[1:]) ** 2 + (y[:-1] - y[1:]) ** 2)])


def distBetweenPointsInArray(point1X, point1Y, point2X, point2Y):
    dist = np.sqrt((point1X - point2X) ** 2 + (point1Y - point2Y) ** 2)
    return dist


def distBetweenPoints(point1, point2):
    dist = np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)
    return dist


def determineAngle(p1, p2):
    normx = ((p2[0] - p1[0]))
    normy = ((p2[1] - p1[1]))
    narcdeg = math.atan2(normy, normx)
    sdegree = ((narcdeg * 180) / math.pi)
    return sdegree


def angleToPixels(angle, screenDist, screenW, screenXY):
    """
    Calculate the number of pixels which equals a specified angle in visual
    degrees, given parameters. Calculates the pixels based on the width of
    the screen. If the pixels are not square, a separate conversion needs
    to be done with the height of the screen.\n
    "angleToPixelsWH" returns pixels for width and height.

    Parameters
    ----------
    angle : float or int
        The angle to convert in visual degrees
    screenDist : float or int
        Viewing distance in cm
    screenW : float or int
        The width of the screen in cm
    screenXY : tuple, ints
        The resolution of the screen (width - x, height - y), pixels

    Returns
    -------
    pix : float
        The number of pixels which corresponds to the visual degree in angle,
        horizontally

    Examples
    --------
    >>> pix = angleToPixels(1, 75, 47.5, (1920,1080))
    >>> pix
    52.912377341863817
    """
    pixSize = screenW / float(screenXY[0])
    angle = np.radians(angle / 2.0)
    cmOnScreen = np.tan(angle) * float(screenDist)
    pix = (cmOnScreen / pixSize) * 2

    return pix


def getFixQual(fixX, fixY, pxPerDeg):
    """
    Calculates the standard deviation and RMS in pixels 
    and in degrees for each fixation in a list of fixations
    Retuns False for a specific fixation if there are less than
    5 samples in the fixation
    
    Parameters
    ------------
    fixX : np.array with np.arrays 
        List of lists containing the x positions of the gaze for each sample
    fixY : np.array with np.arrays 
        List of lists containing the y positions of the gaze for each sample
    pxPerDeg : Float or int
        The number of pixels spanning 1 visual degree
        
        
    Returns
    ------------
    stdvPix : list of floats
        The standard deviation of each fixation in pixel values
    stdvDeg : list of floats
        The standard deviation of each fixation in visual degrees
    RMSPix : list of floats
        The RMS of each fixation in pixel values
    RMSDeg : list of floats
        The RMS of each fixation in visual degrees
    
    Examples
    ------------
    >>> pxPerDeg = 48.0
    >>> 
    >>> fixX = np.array([
            np.array([838.4,  838.9,  839.2,  839.6,  840. ,  840.1]), 
            np.array([809.1,  811.5,  813.2,  814.7,  815.8,  816.6,  817.4])
            ])
    >>> 
    >>> fixY = np.array([
            np.array([977.8,  976. ,  975.1,  974.2,  973.3,  971.9]),
            np.array([992.3,   993.9,   997.4,   999.4,  1002.4,  1004.8,  1007.5])
            ])
    >>> 
    >>> stdvPix, stdvDeg, RMSPix, RMSDeg = getFixQual(fixX, fixY, pxPerDeg)
    >>> 
    >>> print 'stdvPix:', stdvPix
    stdvPix: [1.9866918342924882, 5.8657776073403518]
    >>> 
    >>> print 'stdvDeg:', stdvDeg
    stdvDeg: [0.041389413214426837, 0.12220370015292399]
    >>> 
    >>> print 'RMSPix:', RMSPix
    RMSPix: [1.288409872672502, 3.0069364254447883]
    >>> 
    >>> print 'RMSDeg:', RMSDeg
    RMSDeg: [0.026841872347343792, 0.06264450886343309]

    """

    # Initiate lists
    stdvPix = []
    stdvDeg = []
    RMSPix = []
    RMSDeg = []

    for i, (x, y) in enumerate(zip(fixX, fixY)):
        if len(x) > 5:
            # Get average position
            avX = np.mean(x)
            avY = np.mean(y)

            # Calculate standard deviation
            thetaAv = np.sqrt((x - avX) ** 2 + (y - avY) ** 2)
            stdvPix.append(np.sqrt(np.sum(np.square(thetaAv)) / len(thetaAv)))
            stdvDeg.append(stdvPix[-1] / float(pxPerDeg))

            # Calculate the distance between each sample point in visual degrees
            theta = np.sqrt((x[:-1] - x[1:]) ** 2 + (y[:-1] - y[1:]) ** 2)
            RMSPix.append(np.sqrt(np.sum(np.square(theta)) / len(theta)))
            RMSDeg.append(RMSPix[-1] / float(pxPerDeg))
        else:
            stdvPix.append(False)
            stdvDeg.append(False)
            RMSPix.append(False)
            RMSDeg.append(False)

    return stdvPix, stdvDeg, RMSPix, RMSDeg


def pointAngle(p1, p2):
    """
    Determine the angle of a point (360degrees).
    Assumes that x goes from lower to high (left right)
    Assumes that y goes from high to low (bottom top)
    
    Parameters
    ------------
    p1 : tuple or list of ints or floats
        The x,y coordinates of the start point
    p2 : tuple or list of ints or floats
        The x,y coordinates of the end point

    Returns
    ------------
    angle : float
        The Angle between point 1 (p1) and point 2 (p2)

    Examples
    ------------
    >>> p1 = [0,0]
    >>> p2 = [45,45]
    >>> angle = pointAngle(p1, p2)
    >>> print angle
    315.0

    
    """
    normx = ((p2[0] - p1[0]))
    normy = ((p2[1] - p1[1]))
    narcdeg = math.atan2(normy, normx)
    sdegree = math.degrees(narcdeg)
    angle = sdegree + ((180 - sdegree) * 2)
    if angle > 360:
        angle -= 360
    return angle


def calculateSaccadeCurvature(xSacc, ySacc, pixPerDegree, ignoreDist=0.5, flipY=False):
    """
     Calculates the saccade curvature.\n
    Input a list of xSaccade data points as well as a list of ySaccade data points.\n
    Also ignores any data points within the start and end range (degrees)\n

    Parameters
    ----------
    xSacc: List of lists
        [[],[],[],[],[]], Eeach lists contains xSacc data points
    ySacc: List of lists
        [[],[],[],[],[]], Each lists contains ySacc data points
    pixPerDegree: Float
        The number of pixels per visual degree
    ignoreDist: Float
        All data points which are closer than this value (visual degrees) to either the start or end of saccade are ignored

    Returns
    ----------
    curveData: List of lists
        Containing the saccade curvature for all points in the saccades
    saccAngle: List of Floats
        The angle of the saccade


    Assumptions
    ----------
    Values:
        0 - 180 degrees (clockwise curvature)\n
        0 - -180 degrees (counterclockwhise curvature)
    X values go from left to right\n
    Y values go from top to bottom\n
    """
    curveData = deque([])
    saccAngles = deque([])
    for sacc in range(0, len(xSacc)):
        saccX = xSacc[sacc]
        # Check if there are enough samples in the saccade to calculate curvature
        if len(saccX) < 4:
            curveData.append(np.nan)
            saccAngles.append(np.nan)
            continue
        if flipY == True:
            saccY = [i * -1 for i in ySacc[sacc]]
        else:
            saccY = ySacc[sacc]
        startPos = (saccX[0], saccY[0])
        endPos = (saccX[-1], saccY[-1])
        saccadeAngle = determineAngle(startPos, endPos) * -1
        saccAngle360 = pointAngle((xSacc[sacc][0], ySacc[sacc][0]), (xSacc[sacc][-1], ySacc[sacc][-1]))

        # we calculate point angle for all points except the last point (also exclude first point)
        pointAngles = np.zeros(len(saccX) - 2)
        for pointNr in range(0, len(saccX) - 2):
            point = (saccX[pointNr + 1], saccY[pointNr + 1])
            startDist = distBetweenPoints(startPos, point) / pixPerDegree
            endDist = distBetweenPoints(endPos, point) / pixPerDegree
            # check if the sample is far enough away from start and end position
            # We have the problem with overshoots, the overshoot is sometimes more than ignoreDist
            # this causes the cuvature analysis to be done for then stopped, started and stopped again
            # [0,0,0,0,1,1,1,1,0,0,0,1,1,1,0,0,0,] Where 1 has calculated curvature and 0 is to close
            if min([startDist, endDist]) < ignoreDist:
                pointAngles[pointNr] = 9999
            else:
                pointCurv = (determineAngle(startPos, point) * -1) - saccadeAngle
                if pointCurv > 180:
                    pointCurv -= 360
                elif pointCurv < -180:
                    pointCurv += 360
                pointAngles[pointNr] = pointCurv
        pointAngles = pointAngles[pointAngles < 9999]
        curveData.append(pointAngles)
        saccAngles.append(saccAngle360)
    return curveData, saccAngles


# data = pData
# duplicate = 'Yes'
# eyetracker = 'Tobii'
def parseToLongFormat(data, duplicate='No', eyetracker='Eyelink'):
    """
    Turn a parsed datafile into long data file:
    Deletes the raw data and only keeps events
    """
    data = data.copy()
    # ==============================================================================
    # Delete al the keys with raw data
    # ==============================================================================
    LargeData = ['saccTraceTime', 'saccTraceX', 'saccTraceY', 'saccTracePup',
                 'euclidDist', 'rawPupSize', 'rawTime', 'rawX', 'rawY',
                 'fixTraceTime', 'fixTraceX', 'fixTraceY', 'fixTracePup', 'speed']
    if eyetracker == 'Tobii':
        add = []
        unfilt = ['rawTime', 'GazePointXLeft', 'GazePointYLeft',
                  'ValidityLeft', 'GazePointXRight', 'GazePointYRight',
                  'ValidityRight', 'rawX', 'rawY', 'PupilSizeLeft',
                  'PupilValidityLeft', 'PupilSizeRight', 'PupilValidityRight',
                  'rawPupSize', 'pupValidity', 'gazeValidity']
        variousKeys = ['saccBool', 'fixBool']
        for item in unfilt:
            add.append(item + 'Unfilt')
        for item in variousKeys:
            add.append(item)
        for item in add:
            LargeData.append(item)

    LargeData = ['DK_' + i for i in LargeData]
    LargeData.append('DV_description')
    for key in LargeData:
        if key in data.keys():
            del data[key]
        elif key[3:] in data.keys():
            del data[key[3:]]

    # Delete all headers with spaces
    for key in data.keys():
        if len(key.split()) > 1:
            del data[key]

    # Get the largest number of events for each trial
    trialLengths = np.zeros(len(data))
    for trial in range(len(data)):
        for key in data.keys():
            try:
                if isinstance(data[key][trial], str):
                    keyLen = 1
                else:
                    keyLen = len(data[key][trial])
            except:
                keyLen = 1
                pass

            if keyLen > trialLengths[trial]:
                trialLengths[trial] = keyLen

    # Itterate trough each trial and add an index for the events given
    saccNr = []
    fixNr = []
    for i in range(len(data)):
        saccNr.append(np.arange(len(data['DK_ssacc'][i])) + 1)
        fixNr.append(np.arange(len(data['DK_sFix'][i])) + 1)
    data['DK_saccNr'] = saccNr
    data['DK_fixNr'] = fixNr

    # Initiate a long format data frame
    dataL = pd.DataFrame(index=range(int(np.sum(trialLengths))), columns=data.keys())

    # Itterate through each key and populate the long format data
    for key in data.keys():
        strtIndex = 0
        stopIndex = int(trialLengths[0])
        keyVector = np.empty(len(dataL[key]))
        keyVector[:] = np.NAN
        keyVector = pd.Series(keyVector)
        for trial in range(len(data)):
            try:
                dataLen = len(data[key][trial])
                if isinstance(data[key][trial], str):
                    if duplicate == 'Yes':
                        keyVector[strtIndex:stopIndex] = str(data[key][trial])
                    else:
                        keyVector[strtIndex] = str(data[key][trial])
                else:
                    keyVector[strtIndex:strtIndex + dataLen] = data[key][trial]
            except:
                if duplicate == 'Yes':
                    keyVector[strtIndex:stopIndex] = data[key][trial]
                else:
                    keyVector[strtIndex] = data[key][trial]
            # Update the index for the next data trial indexl
            if trial < len(data) - 1:
                strtIndex += int(trialLengths[trial])
                stopIndex = int(strtIndex + trialLengths[trial + 1])

        # Store the new vector in the dataframe
        dataL[key] = keyVector
    return dataL


def filterDF(df, deleteKeys):
    keys = df.keys()
    for key in keys:
        for delKey in deleteKeys:
            if delKey in key:
                del df[key]
    return df


def eventDetect(time, x, y, val, Hz=300., pxPerDeg=48.,
                maxSaccVel=1000., maxSaccAcc=100000., minSaccDur=10.,
                minFixDur=40., alpha=0.7, beta=0.3, PT=200,
                thresMulti=3):
    '''
    '''
    # =============================================================================
    # Parameters 
    # =============================================================================
    # Input handeling
    val = np.array(val, dtype=bool)

    # Filter settings
    filt = sign.savgol_filter
    filtPolyOrder = 2
    filtWindowLength = minSaccDur * 2

    # Recode the filter variables to number of samples
    minFixDurSamp = int(minFixDur / (1000. / Hz))
    filtWindowLength /= (1000. / Hz)

    # =============================================================================
    # Step 1 - Calculate angular velocities and accelerations. Remove noise
    # =============================================================================
    # Durattion in seconds per sample
    sampDur = np.hstack([[(1000. / Hz) / 1000.], np.diff(time)]) / 1000
    # Filter x coordinates
    xFilt = filt(x, int(filtWindowLength + 1), filtPolyOrder)
    # Filter y coordinates
    yFilt = filt(y, int(filtWindowLength + 1), filtPolyOrder)
    # Get the filtered euclidian distance 
    distDeg = pixDist(xFilt, yFilt) / pxPerDeg
    # Get speed
    speed = distDeg / sampDur
    # get acceleration
    acc = speed / sampDur

    # =============================================================================
    # Step 2 - Iteratively find velocity peaks (samples larger than a threshold)
    # =============================================================================
    while True:
        belowThreshSamples = speed[val][speed[val] < PT]
        Uz = np.average(belowThreshSamples)
        Oz = np.std(belowThreshSamples)
        PTn = Uz + (6 * Oz)
        if PTn - PT < 1:
            PT = PTn
            Uz = np.average(speed[val][speed[val] < PT])
            Oz = np.std(speed[val][speed[val] < PT])
            break
        else:
            PT = PTn

            # =============================================================================
    # Step 3 -  Saccade detection: For each velocity peak
    #   (a) Go back until velocity saccade onset threshold
    #   (b) Go forward until velocity saccade offset threshold (adaptive)
    #   (c) Make sure the saccade duration  minimum saccade duration
    # =============================================================================
    saccBool = np.zeros(len(x), dtype=bool)
    ssaccThresh = Uz + (thresMulti * Oz)
    esaccThresh = 0
    sIdx = 0
    startIndx = 0
    stopIndex = 0
    inEvent = False
    for idx, (s, t) in enumerate(zip(speed, time)):
        # Find the start of the saccade
        if s > ssaccThresh and not inEvent and sIdx <= idx:
            sIdx = idx
            while True and sIdx > 0:
                if speed[sIdx - 1] > speed[sIdx]:
                    startIndx = sIdx
                    inEvent = True
                    break
                sIdx -= 1
            sIdx = idx

        # Determine esacc treshold
        if inEvent and idx + minFixDurSamp < len(speed):
            localMean = np.mean(speed[idx - minFixDurSamp:idx])
            localStd = np.std(speed[idx - minFixDurSamp:idx])
            localNoise = localMean + (3 * localStd)
            esaccThresh = (alpha * ssaccThresh) + (beta * localNoise)

            # Find end of the saccade
            if s < esaccThresh and speed[idx + 1] < s:
                sIdx = idx
                while True and sIdx < len(speed) - 1:
                    if speed[sIdx + 1] > speed[sIdx]:
                        inEvent = False
                        stopIndex = sIdx
                        saccBool[startIndx:stopIndex] = True
                        break
                    sIdx += 1

        # Set the last sample as end of saccade
        elif inEvent and idx + 1 == len(speed):
            saccBool[startIndx:idx] = True
            inEvent = False

    # Itterate trough the saccades and determine missing values, remove saccades
    # And pupulate saccade metrics
    # Still to add in code
    ssaccIdx = []
    esaccIdx = []
    ssacc = []
    esacc = []
    saccDur = []
    saccDist = []
    saccPeakVel = []
    ssaccX = []
    ssaccY = []
    esaccX = []
    esaccY = []
    saccTraceT = []
    saccTraceX = []
    saccTraceY = []
    inEvent = False
    for idx, s in enumerate(saccBool):
        # Find the start of the saccae
        if not inEvent and s:
            ssaccIdx.append(idx)
            inEvent = True

        # Find the end of the saccade
        if inEvent and (not s or idx + 1 == len(saccBool)):
            inEvent = False
            esaccIdx.append(idx)
            # calculate saccade validity 
            sDur = time[esaccIdx[-1]] - time[ssaccIdx[-1]]
            maxVel = np.max(speed[ssaccIdx[-1]:esaccIdx[-1]])
            maxAcc = np.max(acc[ssaccIdx[-1]:esaccIdx[-1]])
            stilness = np.mean(speed[idx - minFixDurSamp:idx]) < PT  # Valid if  True
            allVal = np.sum(~val[ssaccIdx[-1]:esaccIdx[-1]]) == 0  # valid if True

            # Save the saccade if it passes the criteria                               
            if allVal and (sDur > minSaccDur) and (maxVel < maxSaccVel) and stilness and (maxAcc < maxSaccAcc):
                ssacc.append(time[ssaccIdx[-1]])
                esacc.append(time[esaccIdx[-1]])
                saccDur.append(sDur)
                saccPeakVel.append(maxVel)
                ssaccX.append(xFilt[ssaccIdx[-1]])
                ssaccY.append(yFilt[ssaccIdx[-1]])
                esaccX.append(xFilt[esaccIdx[-1]])
                esaccY.append(yFilt[esaccIdx[-1]])
                saccDist.append(np.sqrt((ssaccX[-1] - esaccX[-1]) ** 2 + (ssaccY[-1] - esaccY[-1]) ** 2) / pxPerDeg)
                saccTraceT.append(time[ssaccIdx[-1]:esaccIdx[-1]])
                saccTraceX.append(xFilt[ssaccIdx[-1]:esaccIdx[-1]])
                saccTraceY.append(yFilt[ssaccIdx[-1]:esaccIdx[-1]])

            else:
                saccBool[esaccIdx[-1] - ssaccIdx[-1]] = False
                del ssaccIdx[-1], esaccIdx[-1]

                # Set all samples not a saccade as fixation
    fixBool = ~saccBool

    # =============================================================================
    # Step 4 - Glissade detection: Glissades are detected if
    #   (a) Low-velocity detection: velocity saccade offset threshold
    #       within a fixed time window after saccade offset.
    #   (b) High-velocity detection: velocity peak saccade threshold
    #       within a fixed time window after saccade offset.
    #
    # Glissade detection is skipped and I assign gliassades as part of fixations
    # =============================================================================

    # =============================================================================
    # Step 5 - Fixation detection: Fixations are defined by samples that are
    #   (a) neither saccades, glissades or noise AND
    #   (b) longer than the minimum fixation duration
    #
    #   Adapted to be anything not a saccade and longer than the minimum 
    #   fixation duration   
    # =============================================================================
    # Remove all points that are not valid 
    fixBool[~val] = False
    sfixIdx = []
    efixIdx = []
    sfix = []
    efix = []
    fixDur = []
    fixX = []
    fixY = []
    fixTraceT = []
    fixTraceX = []
    fixTraceY = []
    inEvent = False

    for idx, f in enumerate(fixBool):
        # Find the start of fixation
        if not inEvent and f:
            sfixIdx.append(idx)
            inEvent = True

        # Find the end of the fixation
        if inEvent and (not f or idx + 1 == len(fixBool)):
            inEvent = False
            sfix.append(time[sfixIdx[-1]])
            efixIdx.append(idx)
            efix.append(time[idx])
            fixDur.append(efix[-1] - sfix[-1])
            # Check for fixation parameters
            if fixDur[-1] > minFixDur:
                fixX.append(np.average(xFilt[sfixIdx[-1]:efixIdx[-1]]))
                fixY.append(np.average(yFilt[sfixIdx[-1]:efixIdx[-1]]))
                fixTraceT.append(time[sfixIdx[-1]:efixIdx[-1]])
                fixTraceX.append(xFilt[sfixIdx[-1]:efixIdx[-1]])
                fixTraceY.append(yFilt[sfixIdx[-1]:efixIdx[-1]])
            else:
                del sfixIdx[-1], sfix[-1], efixIdx[-1], efix[-1], fixDur[-1]

    # ==============================================================================
    # Put all the results in a pandas dataframe :)
    # ==============================================================================
    keyPrefix = 'DK_'
    saccColName = ['saccBool', 'ssaccIdx', 'esaccIdx', 'ssacc', 'esacc',
                   'saccDur', 'saccAmp', 'saccPeakVel', 'ssaccX', 'ssaccY',
                   'esaccX', 'esaccY', 'saccTraceTime', 'saccTraceX', 'saccTraceY']
    fixColName = ['fixBool', 'sfixIdx', 'efixIdx', 'sFix', 'eFix',
                  'fixDur', 'fixX', 'fixY', 'fixTraceTime', 'fixTraceX', 'fixTraceY']
    rawColNames = ['rawTime', 'rawX', 'rawY', 'speed']
    saccColName = [keyPrefix + k for k in saccColName]
    fixColName = [keyPrefix + k for k in fixColName]
    rawColNames = [keyPrefix + k for k in rawColNames]
    allCols = np.hstack([saccColName, fixColName, rawColNames])
    eventDF = pd.DataFrame([], columns=allCols)

    # Make a list we can itterate through
    allEvents = [[saccBool], [ssaccIdx], [esaccIdx], [ssacc], [esacc], [saccDur],
                 [saccDist], [saccPeakVel], [ssaccX], [ssaccY], [esaccX], [esaccY], [saccTraceT],
                 [saccTraceX], [saccTraceY], [fixBool], [sfixIdx], [efixIdx], [sfix],
                 [efix], [fixDur], [fixX], [fixY], [fixTraceT], [fixTraceX], [fixTraceY],
                 [time], [xFilt], [yFilt], [speed]]

    for i, k in enumerate(allCols):
        eventDF[allCols[i]] = allEvents[i]

    return eventDF


# ==============================================================================
#  Parser
# ==============================================================================
def parseWrapper(f, kwargs):
    if kwargs['eyetracker'] == 'Eyelink':
        return eyeLinkDataParser(f, **kwargs)
    elif kwargs['eyetracker'] == 'Tobii':
        return dataParserTobii(f, **kwargs)


def dataParserTobii(FILENAME, **par):
    try:
        # ======================================================================
        # Extract parameters, set defaults if parameeter is not given
        # ======================================================================
        # Makes experiment specific expressions for var/start and stop
        var = par.pop('variableKey', 'var')
        startTrial = par.pop('startTrialKey', 'start_trial')
        stopTrial = par.pop('stopTrialKey', 'stop_trial')
        # Get px per degree settings
        screenDist = par.pop('screenDist', 75.)
        screnW = par.pop('screenW', 52.5)
        screenXY = par.pop('screenRes', (1920., 1080.))
        pixPerDegree = angleToPixels(1., screenDist, screnW, screenXY)
        # Get eyetracker information
        eyeHz = par.pop('sampFreq', 300.)
        # Get the information about long format
        convertToLong = par.pop('longFormat', 'No')
        duplicateValues = par.pop('duplicateValues', 'No')

        # ======================================================================
        # Define regular expressions
        # ======================================================================
        regSamples = r'(\d{3,12}.\d{4})\t\t([-]?' + \
                     '\d{0,4})\t([-]?\d{1,4})\t([-]?\d{1})\t([-]?' + \
                     '\d{1,4})\t([-]?\d{1,4})\t([-]?\d{1})\t([-]?' + \
                     '\d{1,4})\t([-]?\d{1,4})\t([-]?\d{1,12}.\d{4})\t' + \
                     '([-]?\d{1})\t([-]?\d{1,12}.\d{4})\t([-]?\d{1})'

        # RegExp for start trial
        regStart = r'(\d{3,12}.\d{4})\t(' + startTrial + ').*\n'

        # RegExp for stop trial
        regStop = r'(\d{3,12}.\d{4})\t(' + stopTrial + ').*\n'

        # RegExp for variables
        regVar = r'(\d{3,12}.\d{4})\t(' + var + ')\s+(.+).*\n'

        # RegExp for messages
        regMsg = r'(\d{3,12}.\d{4})\t+(?!' + var + '|' + startTrial + '|' + stopTrial + ')([a-zA-Z].+).*\\n'

        # ==============================================================================
        # Define keywords
        # ==============================================================================
        keyPrefix = 'DK_'
        varPrefix = 'DV_'
        rawKw = ['rawTime', 'GazePointXLeft', 'GazePointYLeft',
                 'ValidityLeft', 'GazePointXRight', 'GazePointYRight',
                 'ValidityRight', 'rawX', 'rawY', 'PupilSizeLeft',
                 'PupilValidityLeft', 'PupilSizeRight', 'PupilValidityRight']
        addToRaw = ['gazeValidity', 'rawPupSize', 'pupValidity']

        prsKw = ['trialNr', 'sTrial', 'eTrial', 'sMsg', 'eMsg', \
                 'curvature', 'saccAngle', 'stdvPix', 'stdvDeg', 'RMSPix', \
                 'RMSDeg', 'pxDeg', ]

        # Add prefix to avoid double columns
        rawKw = [keyPrefix + k for k in rawKw]
        addToRaw = [keyPrefix + k for k in addToRaw]
        prsKw = [keyPrefix + k for k in prsKw]

        # columns to delete from parsed dataframe
        deleteColumns = ['VALIDATE', '!CAL', '!MODE', 'ELCL', 'RECCFG', 'GAZE_COORDS', \
                         'DISPLAY_COORDS', 'THRESHOLDS', 'DRIFTCORRECT', 'parserDummyVar']

        # ==============================================================================
        # Load data ASCII data to memory
        # ==============================================================================
        with open(FILENAME, 'r') as f:
            raw = f.read()
            # ==============================================================================
            # Exract data with regular expressions then delete raw
            # ==============================================================================
            # Get all samples
            rawSamples = re.findall(regSamples, raw)
            # Get start messages
            startData = re.findall(regStart, raw)
            # Get stop messages
            stopData = re.findall(regStop, raw)
            # Get variables
            varData = re.findall(regVar, raw)
            # Handle all other messages 
            msgData = re.findall(regMsg, raw)

        # ==============================================================================
        # Reformat all the data
        # ==============================================================================
        # Get all samples
        rawSamples = np.array(rawSamples, dtype=float)
        rawData = pd.DataFrame(rawSamples, columns=rawKw, dtype='float64')

        # Get start messages
        startTimes = np.array(startData)[:, 0].astype(float)
        startMsg = np.array(startData)[:, 1]

        # Get stop messages
        stopTimes = np.array(stopData)[:, 0].astype(float)
        stopMsg = np.array(stopData)[:, 1]
        trialNrs = np.arange(1, len(startTimes) + 1)

        # Get variables
        varData.append(('000.0000', 'var', 'parserDummyVar dummy'))
        varData = np.array(varData)
        varTimes = np.array(varData[:, 0], dtype=float)
        varKey = np.array(varData[:, 1], dtype=str)
        del varKey
        varMsg = np.array(varData[:, 2], dtype=str)

        # Handle all other messages 
        msgData.append(('000.0000', 'parserDummyVar2 dummy2'))
        msgData = np.array(msgData)
        msgTimes = np.array(msgData[:, 0], dtype=float)
        msg = np.array(msgData[:, 1], dtype=str)
        msgVars = deque([])
        msgVarTimes = deque([])
        delIdx = np.ones(len(msg), dtype=bool)
        for i, ms in enumerate(msg):
            msLis = ms.split()
            if len(msLis) == 2:
                msgVars.append(ms)
                msgVarTimes.append(msgTimes[i])
                delIdx[i] = False

        # Append the msgVars and msgVarTimes to the variable array
        varMsg = np.hstack((varMsg, np.array(msgVars)))
        varTimes = np.hstack((varTimes, np.array(msgVarTimes)))

        # Delete the excess data
        msg = msg[delIdx]
        msgTimes = msgTimes[delIdx]

        # Extract all unique messages
        unMSG = np.unique(msg)
        uniqueMSG = []
        for m in unMSG:
            delete = False
            for dc in deleteColumns:
                if dc in m:
                    delete = True
            if delete == False:
                uniqueMSG.append(m)
        uniqueMSGHeaders = [varPrefix + h for h in uniqueMSG]

        # =====================================================================
        # Determine raw data validity, pupil size and pupil validity 
        # =====================================================================
        for add in addToRaw:
            rawData[add] = np.zeros(len(rawData))

        # Gaze validity 
        rawData[addToRaw[0]] = np.logical_or(rawData.DK_ValidityLeft.values == 1, rawData.DK_ValidityRight.values == 1)
        rawData[addToRaw[0]] = np.array(rawData[addToRaw[0]].values, dtype=float)

        # Get pupil booleans
        bothPupBool = np.logical_and(rawData.DK_PupilValidityLeft.values == 1,
                                     rawData.DK_PupilValidityRight.values == 1)
        leftPupBool = rawData.DK_PupilValidityLeft.values == 1
        rightPupBool = rawData.DK_PupilValidityRight.values == 1

        # Input pupil size data
        rawData[addToRaw[1]][bothPupBool] = np.average(
            [rawData.DK_PupilSizeLeft.values[bothPupBool], rawData.DK_PupilSizeRight.values[bothPupBool]], axis=0)
        rawData[addToRaw[1]][leftPupBool] = rawData.DK_PupilSizeLeft.values[leftPupBool]
        rawData[addToRaw[1]][rightPupBool] = rawData.DK_PupilSizeRight.values[rightPupBool]

        # set pupil validity 
        rawData[addToRaw[2]] = np.logical_or(rawData.DK_PupilValidityLeft.values == 1,
                                             rawData.DK_PupilValidityRight.values == 1)
        rawData[addToRaw[2]] = np.array(rawData[addToRaw[2]].values, dtype=float)

        # =============================================================================
        # Prealocations and extract some info from data
        # =============================================================================   
        # Deal with the variables
        varMsg = np.array([i.split() for i in varMsg])
        varHeaders = np.array([varPrefix + i[0] for i in varMsg])
        varHeadersUnique = np.unique(varHeaders)

        # Prealocate the parsed data dataframe
        msgHeadersUniqueT = [h + 'TimeStamp' for h in varHeadersUnique]
        cols = np.hstack((prsKw, varHeadersUnique, msgHeadersUniqueT, uniqueMSGHeaders))
        pData = pd.DataFrame(index=range(len(trialNrs)), columns=np.unique(cols))

        # ==============================================================================
        # Start populating the output dataframe. 
        # ==============================================================================
        # Make sure that the number of start and stop  messages match
        # NB: This assumes that if there are unequal numbers there are more stops
        if len(startTimes) != len(stopTimes):
            stopTimes = stopTimes[0:len(startTimes)]
            stopMsg = stopMsg[0:len(startTimes)]

        # start populating the parsed Dataframe with the values defining epochs/trials
        pData[prsKw[0]] = trialNrs  # pData.trialNr
        pData[prsKw[1]] = startTimes  # pData.sTrial
        pData[prsKw[2]] = stopTimes  # pData.eTrial
        pData[prsKw[3]] = startMsg  # pData.sMsg
        pData[prsKw[4]] = stopMsg  # pData.eMsg

        pData[keyPrefix + 'pxDeg'] = pixPerDegree
        eventDF = pd.DataFrame()

        allRawKeys = rawData.keys()
        # ==============================================================================
        # Epoch all data for each trial
        # ==============================================================================
        for i, (start, stop) in enumerate(zip(startTimes, stopTimes)):
            # Extract raw data required for event detection
            epochBool = np.logical_and(rawData[rawKw[0]].values >= start, rawData[rawKw[0]].values <= stop)
            epRawT = rawData[rawKw[0]][epochBool].values  # Sample times
            epRawX = rawData[rawKw[7]][epochBool].values  # Sample x position
            epRawY = rawData[rawKw[8]][epochBool].values  # Sample y position
            epValid = rawData[addToRaw[0]][epochBool].values  # Sample validity

            # Do saccade and fixation detection, based on NYSTRÖM AND HOLMQVIST, 2010 (slightly adapted)        
            eventDF2 = eventDetect(epRawT, epRawX, epRawY, epValid, eyeHz, pixPerDegree)
            # Add all the raw-nonFiltered data from the raw dataframe
            for k in allRawKeys:
                eventDF2[k + 'Unfilt'] = [rawData[k][epochBool].values]
            eventDF = pd.concat([eventDF, eventDF2], ignore_index=True).reset_index(drop=True)

            # Add saccade curvature
            if not np.array(pd.isnull(eventDF['DK_saccTraceX'][i])).all():
                curv, ang = calculateSaccadeCurvature(eventDF['DK_saccTraceX'][i], eventDF['DK_saccTraceY'][i],
                                                      pixPerDegree, flipY=True)
                pData.at[i, keyPrefix + 'curvature'] = [np.median(sacc) for sacc in curv]
                pData.at[i, keyPrefix + 'saccAngle'] = ang

            # Add quality measures sdtv and RMS noise
            if not np.array(pd.isnull(eventDF['DK_fixTraceX'][i])).all():
                stdvP, stdvD, RMSP, RMSD = getFixQual(eventDF['DK_fixTraceX'][i], eventDF['DK_fixTraceY'][i],
                                                      pixPerDegree)
                pData.at[i, keyPrefix + 'stdvPix'] = np.array(stdvP)
                pData.at[i, keyPrefix + 'stdvDeg'] = np.array(stdvD)
                pData.at[i, keyPrefix + 'RMSPix'] = np.array(RMSP)
                pData.at[i, keyPrefix + 'RMSDeg'] = np.array(RMSD)

            # Epoch variables
            varBool = np.logical_and(varTimes >= start, varTimes <= stop)
            varEpochT = varTimes[varBool]
            varEpochMsg = varMsg[varBool]
            varEpochHead = varHeaders[varBool]
            for it, (times, key) in enumerate(zip(varEpochT, varEpochHead)):
                if len(varEpochMsg[it]) == 1:
                    pData.at[i, key] = 'NA'
                elif len(varEpochMsg[it]) == 2:
                    pData.at[i, key] = str(varEpochMsg[it][1])
                elif len(varEpochMsg[it]) > 2:
                    pData.at[i, key] = str(varEpochMsg[it][1:])
                pData.at[i, key + 'TimeStamp'] = times

            # Epoch messages
            msgBool = np.logical_and(msgTimes >= start, msgTimes <= stop)
            msgEpochT = msgTimes[msgBool]
            msgEpoch = msg[msgBool]
            for times, key in zip(msgEpochT, msgEpoch):
                if key in uniqueMSG:
                    pData.at[i, varPrefix + key] = times

        # =============================================================================
        # Add The final things to the parsed dataframe
        # =============================================================================
        # Add the events to the parsed data frame
        for k in eventDF.keys():
            if not k == 'index':
                pData[k] = eventDF[k]

        # Add included trial column
        pData[keyPrefix + 'includedTrial'] = True

        # Filter the columns we dont want
        pData = filterDF(pData, deleteColumns)
        pData.columns = pData.columns.str.replace("\r", '')

        # Turn values into numeric if possible
        for k in pData.keys():
            pData[k] = pd.to_numeric(pData[k], errors='ignore')

        # Convert data to long format
        if convertToLong == 'Yes':
            parsedLong = parseToLongFormat(pData, duplicateValues, 'Tobii')
        else:
            parsedLong = False

        # No error
        error = False

    except:  # Exception as e:
        pData = False
        rawData = False
        parsedLong = False
        error = traceback.format_exc()

    return FILENAME, pData, rawData, parsedLong, error


def eyeLinkDataParser(FILENAME, **par):
    try:
        # ==========================================================================
        # Extract parameters, set defaults if parameeter is not given
        # ==========================================================================
        regSamples = r'(\d{3,12})\t\s+(\d+\..)\t\s+(\d+\..)\t\s+(\d+\..).+\n'
        regEfix = r'EFIX\s+[LR]\s+(\d+)\t(\d+)\t(\d+)\t\s+(.+)\t\s+(.+)\t\s+(\d+)\n'
        regEsacc = r'ESACC\s+[LR]\s+(\d+)\t(\d+)\t(\d+)\t\s+(\d+.?\d+)\t\s+(\d+.?\d+)\t\s+(\d+.?\d+)\t\s+(\d+.?\d+)\t\s+(\d+.?\d+)\t\s+(\d+)\n'
        regEblink = r'EBLINK\s+[LR]\s+(\d+)\t(\d+)\t(\d+)\n'

        # Makes experiment specific expressions for var/start and stop
        var = par.pop('variableKey', 'var')
        startTrial = par.pop('startTrialKey', 'start_trial')
        stopTrial = par.pop('stopTrialKey', 'stop_trial')

        # RegExp for start trial
        regStart = 'MSG\\t(\d+)\s+(' + startTrial + ').*\\n'
        # RegExp for stop trial
        regStop = 'MSG\\t(\d+)\s+(' + stopTrial + ').*\\n'
        # RegExp for variables
        regVar = 'MSG\\t(\d+)\s+(' + var + ')\s+(.+).*\\n'
        # RegExp for messages
        regMsg = 'MSG\\t(\d+)\s+(?!' + var + '|' + startTrial + '|' + stopTrial + ')(.+).*\\n'

        # Get px per degree settings
        screenDist = par.pop('screenDist', 75.)
        screnW = par.pop('screenW', 52.5)
        screenXY = par.pop('screenRes', (1920., 1080.))
        pixPerDegree = angleToPixels(1., screenDist, screnW, screenXY)
        pxPerDegMode = par.pop('pxMode', 'Automatic')
        # Get eyetracker information
        eyeHz = par.pop('sampFreq', 1000.)

        # Get the information about long format
        convertToLong = par.pop('longFormat', 'No')
        duplicateValues = par.pop('duplicateValues', 'No')

        # ==============================================================================
        # Define keywords
        # ==============================================================================
        keyPrefix = 'DK_'
        varPrefix = 'DV_'
        rawKw = ['rawTime', 'rawX', 'rawY', 'rawPupSize']
        fixKw = ['sFix', 'eFix', 'fixDur', 'fixX', 'fixY', 'fixPup']
        saccKw = ['ssacc', 'esacc', 'saccDur', 'ssaccX', 'ssaccY', 'esaccX', \
                  'esaccY', 'saccAmp', 'peakVelocity']
        blinkKw = ['sBlink', 'eBlink', 'blinkDur']
        FixTraceKw = ['fixTraceTime', 'fixTraceX', 'fixTraceY', 'fixTracePup']
        SaccTraceKw = ['saccTraceTime', 'saccTraceX', 'saccTraceY', \
                       'saccTracePup']
        prsKw = ['trialNr', 'sTrial', 'eTrial', 'sMsg', 'eMsg', \
                 'esacc', 'ssacc', 'saccDur', 'ssaccX', 'ssaccY', \
                 'esaccX', 'esaccY', 'saccAmp', 'peakVelocity', \
                 'saccTraceTime', 'saccTraceX', 'saccTraceY', \
                 'saccTracePup', 'fixTraceTime', 'fixTraceX', 'fixTraceY', \
                 'fixTracePup', 'sFix', 'eFix', 'fixDur', 'fixX', \
                 'fixY', 'fixPup', 'sBlink', 'eBlink', 'blinkDur', \
                 'rawX', 'rawY', 'rawTime', 'rawPupSize', 'speed', \
                 'curvature', 'saccAngle', 'stdvPix', 'stdvDeg', 'RMSPix', \
                 'RMSDeg', 'pxDeg', ]

        # Add prefix to avoid double columns
        rawKw = [keyPrefix + k for k in rawKw]
        fixKw = [keyPrefix + k for k in fixKw]
        saccKw = [keyPrefix + k for k in saccKw]
        blinkKw = [keyPrefix + k for k in blinkKw]
        fixTraceKw = [keyPrefix + k for k in FixTraceKw]
        saccTraceKw = [keyPrefix + k for k in SaccTraceKw]
        prsKw = [keyPrefix + k for k in prsKw]

        # columns to delete from parsed dataframe
        deleteColumns = ['VALIDATE', '!CAL', '!MODE', 'ELCL', 'RECCFG', 'GAZE_COORDS', \
                         'DISPLAY_COORDS', 'THRESHOLDS', 'DRIFTCORRECT', 'parserDummyVar']

        # ==============================================================================
        # Load data ASCII data to memory
        # ==============================================================================
        with open(FILENAME, 'r') as f:
            raw = f.read()
            # ==============================================================================
            # Check if \r\n is in raw, in that case replace \n in regular expression 
            # with \r (only saccade events)
            # ==============================================================================
            if '\r\n' in raw:
                regEfix = regEfix[:-1] + 'r'
                regEsacc = regEsacc[:-1] + 'r'
                regEblink = regEblink[:-1] + 'r'
                # ==============================================================================
            # Exract data with regular expressions then delete raw
            # ==============================================================================
            # Get all samples
            rawSamples = re.findall(regSamples, raw)
            # Get fixation info
            efixData = re.findall(regEfix, raw)
            # Get saccade info
            esaccData = re.findall(regEsacc, raw)
            # Get blink info
            blinkData = re.findall(regEblink, raw)
            # Get start and stop messages
            startData = re.findall(regStart, raw)
            stopData = re.findall(regStop, raw)
            # Get variables
            varData = re.findall(regVar, raw)
            # Handle all other messages 
            msgData = re.findall(regMsg, raw)

        # ==============================================================================
        # Reformat all the data
        # ==============================================================================
        # Get all samples
        rawSamples = np.array(rawSamples, dtype=float)
        rawData = pd.DataFrame(rawSamples, columns=rawKw, dtype='float64')

        # Get fixation info
        efixData = np.array(efixData, dtype=float)
        if len(efixData) == 0:
            efixData = np.array([[0 for i in range(len(fixKw))]])
        fixData = pd.DataFrame(efixData, columns=fixKw, dtype='float64')

        # Get saccade info
        esaccData = np.array(esaccData, dtype=float)
        if len(esaccData) == 0:
            esaccData = np.array([[0 for i in range(len(saccKw))]])
        saccData = pd.DataFrame(esaccData, columns=saccKw, dtype='float64')

        # Get blink info
        blinkData = np.array(blinkData, dtype=float)
        if len(blinkData) == 0:
            blinkData = np.array([[0 for i in range(len(blinkKw))]])
        blinkData = pd.DataFrame(blinkData, columns=blinkKw, dtype='float64')

        # Get start and stop messages
        startTimes = np.array(startData)[:, 0].astype(float)
        startMsg = np.array(startData)[:, 1]
        stopTimes = np.array(stopData)[:, 0].astype(float)
        stopMsg = np.array(stopData)[:, 1]
        trialNrs = np.arange(1, len(startTimes) + 1)

        # Get variables
        varData.append(('000000', 'var', 'parserDummyVar dummy'))
        varData = np.array(varData)
        varTimes = np.array(varData[:, 0], dtype=float)
        varKey = np.array(varData[:, 1], dtype=str)
        del varKey
        varMsg = np.array(varData[:, 2], dtype=str)

        # Handle all other messages 
        msgData = np.array(msgData)
        msgTimes = np.array(msgData[:, 0], dtype=float)
        msg = np.array(msgData[:, 1], dtype=str)
        msgVars = deque([])
        msgVarTimes = deque([])
        delIdx = np.ones(len(msg), dtype=bool)
        for i, ms in enumerate(msg):
            msLis = ms.split()
            if len(msLis) == 2:
                msgVars.append(ms)
                msgVarTimes.append(msgTimes[i])
                delIdx[i] = False

        # Append the msgVars and msgVarTimes to the variable array
        varMsg = np.hstack((varMsg, np.array(msgVars)))
        varTimes = np.hstack((varTimes, np.array(msgVarTimes)))

        # Delete the excess data
        msg = msg[delIdx]
        msgTimes = msgTimes[delIdx]

        # Extract all unique messages
        unMSG = np.unique(msg)
        uniqueMSG = []
        for m in unMSG:
            delete = False
            for dc in deleteColumns:
                if dc in m:
                    delete = True
            if delete == False:
                uniqueMSG.append(m)
        uniqueMSGHeaders = [varPrefix + h for h in uniqueMSG]

        # =============================================================================
        # Prealocations and extract some info from data
        # =============================================================================   
        # Determine pixels per degree (using amplitude)
        if pxPerDegMode == 'Automatic':
            dist = distBetweenPointsInArray(saccData[saccKw[3]].values, saccData[saccKw[4]].values,
                                            saccData[saccKw[5]].values, saccData[saccKw[6]].values)
            saccAmp = saccData[saccKw[7]].values
            dist = dist[saccAmp != 0]
            saccAmp = saccAmp[saccAmp != 0]
            pixPerDegree = np.median(dist / saccAmp)

        # Deal with the variables
        varMsg = np.array([i.split() for i in varMsg])
        varHeaders = np.array([varPrefix + i[0] for i in varMsg])
        varHeadersUnique = np.unique(varHeaders)

        # Prealocate the parsed data dataframe
        msgHeadersUniqueT = [h + 'TimeStamp' for h in varHeadersUnique]
        cols = np.hstack((prsKw, varHeadersUnique, msgHeadersUniqueT, uniqueMSGHeaders))
        pData = pd.DataFrame(index=range(len(trialNrs)), columns=np.unique(cols))

        # ==============================================================================
        # Start populating the output dataframe. 
        # ==============================================================================
        # Make sure that the number of start and stop  messages match
        # NB: This assumes that if there are unequal numbers there are more stops
        if len(startTimes) != len(stopTimes):
            stopTimes = stopTimes[0:len(startTimes)]
            stopMsg = stopMsg[0:len(startTimes)]

        # start populating the parsed Dataframe with the values defining epochs/trials
        pData[prsKw[0]] = trialNrs  # pData.trialNr
        pData[prsKw[1]] = startTimes  # pData.sTrial
        pData[prsKw[2]] = stopTimes  # pData.eTrial
        pData[prsKw[3]] = startMsg  # pData.sMsg
        pData[prsKw[4]] = stopMsg  # pData.eMsg

        pData[keyPrefix + 'pxDeg'] = pixPerDegree
        # ==============================================================================
        # Epoch all data for each trial
        # ==============================================================================
        for i, (start, stop) in enumerate(zip(startTimes, stopTimes)):
            # Epoch fixations
            fixStartEpoch = np.logical_or(fixData[fixKw[0]] >= start, fixData[fixKw[1]] >= start)
            fixEndEpoch = np.logical_or(fixData[fixKw[0]] <= stop, fixData[fixKw[1]] <= stop)
            fixEpoch = fixData.loc[np.logical_and(fixStartEpoch, fixEndEpoch)]
            for key in fixKw:
                pData.at[i, key] = fixEpoch[key].values

            # Epoch saccades  
            saccStartEpoch = np.logical_or(saccData[saccKw[0]] >= start, saccData[saccKw[1]] >= start)
            saccStopEpoch = np.logical_or(saccData[saccKw[0]] <= stop, saccData[saccKw[1]] <= stop)
            saccEpoch = saccData.loc[np.logical_and(saccStartEpoch, saccStopEpoch)]
            for key in saccKw:
                pData.at[i, key] = saccEpoch[key].values

            # Epoch blinks
            blinkEpoch = blinkData.loc[np.logical_and(blinkData[blinkKw[0]] >= start, blinkData[blinkKw[1]] <= stop)]
            for key in blinkKw:
                pData.at[i, key] = blinkEpoch[key].values

            # Get the start and stop time for the trial (to include all data)
            if len(fixEpoch[fixKw[0]]) > 0 and len(saccEpoch[saccKw[0]]) > 0:
                eStart = np.min(
                    [start, fixEpoch[fixKw[0]][fixEpoch.index.min()], saccEpoch[saccKw[0]][saccEpoch.index.min()]])
                eStop = np.max(
                    [stop, fixEpoch[fixKw[1]][fixEpoch.index.max()], saccEpoch[saccKw[1]][saccEpoch.index.max()]])
            else:
                eStart = start
                eStop = stop
            epochData = rawData.loc[np.logical_and(rawData[rawKw[0]] >= eStart, rawData[rawKw[0]] <= eStop)]

            # Extract the raw data
            for key in rawKw:
                pData.at[i, key] = epochData[key].values

            # Extract fixation traces
            sFix = pData[fixKw[0]][i]
            eFix = pData[fixKw[1]][i]
            epTime = epochData[rawKw[0]].values
            fixBools = [np.logical_and(epTime >= s, epTime <= e) for (s, e) in zip(sFix, eFix)]
            for key, rKey in zip(fixTraceKw, rawKw):
                fixTraces = [epochData[rKey][b].values for b in fixBools]
                pData.at[i, key] = fixTraces

            # Extract Saccade traces
            sSacc = pData[saccKw[0]][i]
            eSacc = pData[saccKw[1]][i]
            saccBools = [np.logical_and(epTime >= s, epTime <= e) for (s, e) in zip(sSacc, eSacc)]
            for key, rKey in zip(saccTraceKw, rawKw):
                saccTraces = [epochData[rKey][b].values for b in saccBools]
                pData.at[i, key] = saccTraces

            # Calculate euclidian distance between samples (if more than 4 samples)
            if len(pData[rawKw[1]][i]) > 4:
                p1X = np.append(pData[rawKw[1]][i], 0)[:-1]
                p1Y = np.append(pData[rawKw[2]][i], 0)[:-1]
                p2X = np.append(pData[rawKw[1]][i][0], pData[rawKw[1]][i])[:-1]
                p2Y = np.append(pData[rawKw[2]][i][0], pData[rawKw[2]][i])[:-1]
                pData.at[i, keyPrefix + 'speed'] = (distBetweenPointsInArray(p1X, p1Y, p2X, p2Y) / pixPerDegree) / (
                        (1000. / eyeHz) / 1000.)
            else:
                pData.at[i, keyPrefix + 'speed'] = []

            # Add saccade curvature
            if not np.array(pd.isnull(pData[saccTraceKw[1]][i])).all():
                curv, ang = calculateSaccadeCurvature(pData[saccTraceKw[1]][i], pData[saccTraceKw[2]][i], pixPerDegree,
                                                      flipY=True)
                pData.at[i, keyPrefix + 'curvature'] = [np.median(sacc) for sacc in curv]
                pData.at[i, keyPrefix + 'saccAngle'] = ang

            # Add quality measures sdtv and RMS noise
            if not np.array(pd.isnull(pData[fixTraceKw[1]][i])).all():
                stdvP, stdvD, RMSP, RMSD = getFixQual(pData[fixTraceKw[1]][i], pData[fixTraceKw[2]][i], pixPerDegree)
                pData.at[i, keyPrefix + 'stdvPix'] = np.array(stdvP)
                pData.at[i, keyPrefix + 'stdvDeg'] = np.array(stdvD)
                pData.at[i, keyPrefix + 'RMSPix'] = np.array(RMSP)
                pData.at[i, keyPrefix + 'RMSDeg'] = np.array(RMSD)

            # Epoch variables
            varBool = np.logical_and(varTimes >= start, varTimes <= stop)
            varEpochT = varTimes[varBool]
            varEpochMsg = varMsg[varBool]
            varEpochHead = varHeaders[varBool]
            for it, (times, key) in enumerate(zip(varEpochT, varEpochHead)):
                if len(varEpochMsg[it]) == 1:
                    pData.at[i, key] = 'NA'
                elif len(varEpochMsg[it]) == 2:
                    pData.at[i, key] = varEpochMsg[it][1]
                elif len(varEpochMsg[it]) > 2:
                    pData.at[i, key] = varEpochMsg[it][1:]
                pData.at[i, key + 'TimeStamp'] = times

            # Epoch messages
            msgBool = np.logical_and(msgTimes >= start, msgTimes <= stop)
            msgEpochT = msgTimes[msgBool]
            msgEpoch = msg[msgBool]
            for times, key in zip(msgEpochT, msgEpoch):
                if key in uniqueMSG:
                    pData.at[i, varPrefix + key] = times

        # =============================================================================
        # Add included trial column
        # =============================================================================
        pData[keyPrefix + 'includedTrial'] = True

        # Filter the columns we dont want
        pData = filterDF(pData, deleteColumns)
        pData.columns = pData.columns.str.replace("\r", '')

        # Turn values into numeric if possible
        for k in pData.keys():
            pData[k] = pd.to_numeric(pData[k], errors='ignore')

        # Convert data to long format
        if convertToLong == 'Yes':
            parsedLong = parseToLongFormat(pData, duplicateValues, 'Eyelink')
        else:
            parsedLong = False

        # No error
        error = False

    except:  # Exception as e:
        pData = False
        rawData = False
        parsedLong = False
        error = traceback.format_exc()

    return FILENAME, pData, rawData, parsedLong, error
